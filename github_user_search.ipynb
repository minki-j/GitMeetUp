{
 "cells": [
  {
<<<<<<< HEAD
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page 1. Total users: 0\n",
      "Fetching page 2. Total users: 100\n",
      "Fetching page 3. Total users: 200\n",
      "Fetching page 4. Total users: 300\n",
      "Fetching page 5. Total users: 400\n",
      "Fetching page 6. Total users: 500\n",
      "Fetching page 7. Total users: 600\n",
      "Fetching page 8. Total users: 700\n",
      "Fetching page 9. Total users: 800\n",
      "Fetching page 10. Total users: 900\n",
      "Fetching page 11. Total users: 1000\n",
      "Failed to fetch repositories: 403\n",
      "<Response [403]>\n"
     ]
    }
   ],
=======
=======
>>>>>>> ab00ed3 (fetch and filter users)
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch users based on location\n",
    "\n",
    "Due to the Github API's limit of returning only the first 1000 items, we must divide the query into intervals based on the account creation dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def generate_date_intervals(\n",
    "    interval_days,\n",
    "    start_year=2008,\n",
    "    end_date=datetime.now(),\n",
    "):\n",
    "    dates = []\n",
    "    end_year = end_date.year\n",
    "\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        for month in range(1, 13):\n",
    "            # Skip months beyond the end date in the final year\n",
    "            if year == end_year and month > end_date.month:\n",
    "                break\n",
    "\n",
    "            # Calculate the number of days in the current month\n",
    "            if month == 12:\n",
    "                days_in_month = (\n",
    "                    datetime(year + 1, 1, 1) - datetime(year, month, 1)\n",
    "                ).days\n",
    "            else:\n",
    "                days_in_month = (\n",
    "                    datetime(year, month + 1, 1) - datetime(year, month, 1)\n",
    "                ).days\n",
    "\n",
    "            # Adjust the days in the month if it's the current month and year\n",
    "            if year == end_date.year and month == end_date.month:\n",
    "                days_in_month = end_date.day\n",
    "\n",
    "            # Loop through the month in intervals of `interval_days`\n",
    "            for day in range(1, days_in_month + 1, interval_days):\n",
    "                start_date = datetime(year, month, day)\n",
    "                # Ensure the end date does not exceed the month or the specified end date\n",
    "                end_interval_date = min(\n",
    "                    start_date + timedelta(days=interval_days-1),\n",
    "                    datetime(year, month, days_in_month) + timedelta(days=1),\n",
    "                    end_date\n",
    "                    + timedelta(days=1),  # Ensure we don't go beyond the end_date\n",
    "                )\n",
    "\n",
    "                # Format the dates as strings and add them to the list\n",
    "                dates.append(\n",
    "                    f\"{start_date.strftime('%Y-%m-%d')}..{end_interval_date.strftime('%Y-%m-%d')}\"\n",
    "                )\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "def get_page_num(url):\n",
    "    query_string = urlparse(url).query\n",
    "    params = parse_qs(query_string)\n",
    "    return params.get(\"page\", [None])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
>>>>>>> ab00ed3 (fetch and filter users)
=======
>>>>>>> ab00ed3 (fetch and filter users)
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "\n",
    "base_url = \"https://api.github.com/search/users?\"\n",
    "\n",
    "users_in_montreal = []\n",
    "page = 1\n",
    "\n",
    "while True:\n",
    "    print(f\"Fetching page {page}. Total users: {len(users_in_montreal)}\")\n",
    "    # Send the GET request to the GitHub API with the current page number\n",
    "    response = requests.get(\n",
    "        base_url,\n",
    "        params={\n",
    "            \"q\": \"location:montreal followers:>5 followers:<10\",\n",
    "            \"page\": page,\n",
    "            \"per_page\": 100,\n",
    "            \"sort\": \"followers updated\",\n",
    "            \"order\": \"asc\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # # wait for 30 seconds\n",
    "    # if response.status_code == 403:\n",
    "    #     print(response)\n",
    "    #     print(\"Rate limit exceeded. Waiting for 60 seconds...\")\n",
    "    #     time.sleep(61)\n",
    "    #     continue\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        users = response.json()[\"items\"]\n",
    "\n",
    "        if not users:\n",
    "            break\n",
    "\n",
    "        users_in_montreal.extend(users)\n",
    "\n",
    "        page += 1\n",
    "    else:\n",
    "        print(f\"Failed to fetch repositories: {response.status_code}\")\n",
    "        print(response)\n",
    "        break\n",
    "\n",
    "# Save the list of users to a file\n",
    "with open(\"users_in_montreal_sorted_follower5to10.json\", \"w\") as file:\n",
    "    json.dump(users_in_montreal, file, indent=4)"
=======
=======
>>>>>>> ab00ed3 (fetch and filter users)
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "token = os.getenv(\"GITHUB_TOKEN\")\n",
    "headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "base_url = \"https://api.github.com/search/users?\"\n",
    "location = \"montreal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_users_from_github(location, date, base_url, headers):\n",
    "    users = []\n",
    "    log = []\n",
    "\n",
    "    for idx, date in enumerate(reversed(dates)):\n",
    "        log_for_date = {\"date\": date, \"messages\": [], \"overflow\": False}\n",
    "        next_url = \"first_page\"\n",
    "        while True:\n",
    "            if next_url is not None and next_url != \"first_page\":\n",
    "                response = requests.get(next_url, headers=headers)\n",
    "            elif next_url == \"first_page\":\n",
    "                response = requests.get(\n",
    "                    base_url,\n",
    "                    headers=headers,\n",
    "                    params={\n",
    "                        \"q\": f\"location:{location} created:{date}\",\n",
    "                        \"page\": 1,\n",
    "                        \"per_page\": 100,\n",
    "                        \"sort\": \"joined\",\n",
    "                        \"order\": \"desc\",\n",
    "                    },\n",
    "                )\n",
    "                last_url = response.links.get(\"last\", {}).get(\"url\")\n",
    "                last_page_num = get_page_num(last_url)\n",
    "                if last_page_num == 10:\n",
    "                    log_for_date[\"overflow\"] = True\n",
    "            else:\n",
    "                break\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                users = response.json()[\"items\"]\n",
    "                if users:\n",
    "                    users.extend(users)\n",
    "                    log_for_date[\"messages\"].append(f\"{len(users)} total user added\")\n",
    "                else:\n",
    "                    if next_url != \"first_page\":\n",
    "                        log_for_date[\"messages\"].append(f\"NO USER in: {next_url}\")\n",
    "                next_url = response.links.get(\"next\", {}).get(\"url\")\n",
    "            else:\n",
    "                print(f\"Failed to fetch repositories: {response.status_code}\")\n",
    "                print(response)\n",
    "                print(\"Waiting for 60 seconds\")\n",
    "                time.sleep(60)\n",
    "            \n",
    "            log.append(log_for_date)\n",
    "\n",
    "            if response.headers.get(\"X-RateLimit-Remaining\") == \"0\":\n",
    "                # print(\"Rate limit reached. Waiting for 60 seconds\")\n",
    "                print(\n",
    "                    f\"Processed {idx + 1} out of {len(dates)} / Total users: {len(users)}\"\n",
    "                )\n",
    "\n",
    "                # Save the list of users to a file\n",
    "                with open(f\"./data/users_in_{location}.json\", \"w\") as file:\n",
    "                    json.dump(users, file, indent=4)\n",
    "\n",
    "                # Save the log to a file\n",
    "                with open(f\"./data/log_{location}.json\", \"w\") as file:\n",
    "                    json.dump(log, file, indent=4)\n",
    "\n",
    "                time.sleep(60)\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = generate_date_intervals(interval_days=60)\n",
    "users = fetch_users_from_github(location, dates, base_url, headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deduplicate users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "location = \"montreal\"\n",
    "\n",
    "with open(f\"./data/users_in_{location}.json\") as file:\n",
    "    users = json.load(file)\n",
    "\n",
    "user_ids = [user[\"id\"] for user in users]\n",
    "print(f\"Total users: {len(users)}\")\n",
    "print(f\"Total unique users: {len(set(user_ids))}\")\n",
    "\n",
    "if len(users) != len(set(user_ids)):\n",
    "    duplicated_user_ids = []\n",
    "    for user_id in set(user_ids):\n",
    "        if user_ids.count(user_id) > 1:\n",
    "            duplicated_user_ids.append(user_id)\n",
    "    print(f\"Total duplicated users: {len(duplicated_user_ids)}\")\n",
    "\n",
    "    # remove duplicated users\n",
    "    if len(duplicated_user_ids) > 0:\n",
    "        deduplicated_users = []\n",
    "        seen_user_ids = set()\n",
    "\n",
    "        for user in users:\n",
    "            # If the user's ID hasn't been seen, add the user to the deduplicated list and mark the ID as seen\n",
    "            # This will keep the order of the users list\n",
    "            if user[\"id\"] not in seen_user_ids:\n",
    "                deduplicated_users.append(user)\n",
    "                seen_user_ids.add(user[\"id\"])\n",
    "\n",
    "        with open(f\"./data/users_in_{location}_deduplicated.json\", \"w\") as file:\n",
    "            json.dump(deduplicated_users, file, indent=4)\n",
    "\n",
    "        print(f\"Total unique users after deduplication: {len(deduplicated_users)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter inactive users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def convert_to_est(utc_epoch_seconds):\n",
    "    if type(utc_epoch_seconds) != int:\n",
    "        utc_epoch_seconds = int(utc_epoch_seconds)\n",
    "        \n",
    "    # Convert UTC epoch seconds to a datetime object\n",
    "    utc_datetime = datetime.datetime.fromtimestamp(\n",
    "        utc_epoch_seconds, tz=datetime.timezone.utc\n",
    "    )\n",
    "\n",
    "    # Define the EST timezone\n",
    "    est_tz = datetime.timezone(datetime.timedelta(hours=-5))\n",
    "\n",
    "    # Convert the UTC datetime to EST\n",
    "    est_datetime = utc_datetime.astimezone(est_tz)\n",
    "\n",
    "    return est_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user: hussnainzamanProcessing user: DorinP28\n",
      "Processing user: fboucheros\n",
      "Processing user: fSosaRey\n",
      "Processing user: jakelid\n",
      "Processing user: RahulRaviHulli\n",
      "Processing user: hamid194\n",
      "Processing user: 0530486237\n",
      "Processing user: WilliamRT7\n",
      "Processing user: 3mblay\n",
      "Processing user: yananazarenko417\n",
      "Processing user: Venkat-Ankem\n",
      "Processing user: Diyoraaaaaaaaaaaaaaaaaaaaaaa\n",
      "Processing user: agam-s24\n",
      "Processing user: gregory-pierre\n",
      "Processing user: EyadAbouKer\n",
      "Processing user: yalaoui356\n",
      "Processing user: Carpen-Them-Diemz\n",
      "Processing user: aitlassri\n",
      "Processing user: haejin-unity\n",
      "Processing user: alex-cruel\n",
      "Processing user: frank-duq\n",
      "Processing user: bagerathi28\n",
      "Processing user: OmarCE11\n",
      "Processing user: LSBarreiros\n",
      "Processing user: sdunberr\n",
      "403\n",
      "0\n",
      "1718820125\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'datetime.datetime' has no attribute 'datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mstatus_code)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-RateLimit-Remaining\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mconvert_to_est\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX-RateLimit-Reset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m, in \u001b[0;36mconvert_to_est\u001b[0;34m(utc_epoch_seconds)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(utc_epoch_seconds)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Convert UTC epoch seconds to a datetime object\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m utc_datetime \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatetime\u001b[49m\u001b[38;5;241m.\u001b[39mfromtimestamp(\n\u001b[1;32m      8\u001b[0m     utc_epoch_seconds, tz\u001b[38;5;241m=\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mtimezone\u001b[38;5;241m.\u001b[39mutc\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Define the EST timezone\u001b[39;00m\n\u001b[1;32m     12\u001b[0m est_tz \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mtimezone(datetime\u001b[38;5;241m.\u001b[39mtimedelta(hours\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'datetime.datetime' has no attribute 'datetime'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user: ytmicrocom\n",
      "Processing user: Jessica22Jane\n",
      "Processing user: mattpagani\n",
      "Processing user: ShayneLussier\n",
      "Processing user: cb-wd-30\n",
      "Processing user: volodymyr-polishchuk-x\n",
      "Processing user: DrToddLee\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "token = os.getenv(\"GITHUB_TOKEN\")\n",
    "headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "base_url = \"https://api.github.com/search/users?\"\n",
    "location = \"montreal\"\n",
    "response = requests.get(\"https://api.github.com/users/twinjaysad\", headers=headers)\n",
    "print(response.status_code)\n",
    "print(response.headers[\"X-RateLimit-Remaining\"])\n",
    "print(convert_to_est(response.headers[\"X-RateLimit-Reset\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "token = os.getenv(\"GITHUB_TOKEN\")\n",
    "headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "base_url = \"https://api.github.com/search/users?\"\n",
    "location = \"montreal\"\n",
    "\n",
    "def process_user(user):\n",
    "    print(f\"Processing user: {user['login']}\")\n",
    "    response = requests.get(user[\"url\"], headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        user_info = response.json()\n",
    "        if user_info[\"updated_at\"] > threshold_date:\n",
    "            return (\"active\", user)\n",
    "        else:\n",
    "            return (\"inactive\", user)\n",
    "    else:\n",
    "        print(f\"Failed to fetch user info: {response.status_code}\")\n",
    "        return (\"failed\", user)\n",
    "\n",
    "\n",
    "location = \"montreal\"\n",
    "with open(f\"./data/users_in_{location}_deduplicated.json\") as file:\n",
    "    users = json.load(file)\n",
    "\n",
    "threshold_day = 180\n",
    "threshold_date = (datetime.now() - timedelta(days=threshold_day)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def save_processed_data(active_users, remaining_users):\n",
    "    with open(f\"./data/active_users_{location}.json\", \"w\") as file:\n",
    "        json.dump(active_users, file, indent=4)\n",
    "\n",
    "    with open(f\"./data/remaining_users_{location}.json\", \"w\") as file:\n",
    "        json.dump(remaining_users, file, indent=4)\n",
    "\n",
    "\n",
    "class RateLimitExceeded(Exception):\n",
    "    pass\n",
    "\n",
    "countdown = 10\n",
    "def filter_users_in_parallel(users):\n",
    "    active_users = []\n",
    "    remaining_users = []\n",
    "    executor = concurrent.futures.ThreadPoolExecutor(max_workers=3)\n",
    "\n",
    "    try:\n",
    "        future_to_user = {executor.submit(process_user, user): user for user in users}\n",
    "        for future in concurrent.futures.as_completed(future_to_user):\n",
    "            status, user = future.result()\n",
    "\n",
    "            if status == \"active\":\n",
    "                active_users.append(user)\n",
    "            else:\n",
    "                remaining_users.append(user)\n",
    "\n",
    "            rate_limit_remaining = int(response.headers.get(\"X-RateLimit-Remaining\", 0))\n",
    "            if rate_limit_remaining == 0:\n",
    "                print(\"Rate limit exceeded. Saving processed data...\")\n",
    "                save_processed_data(active_users, remaining_users)\n",
    "                raise RateLimitExceeded\n",
    "\n",
    "    except RateLimitExceeded:\n",
    "        executor.shutdown(wait=True)\n",
    "    finally:\n",
    "        executor.shutdown(wait=True)\n",
    "\n",
    "    return active_users, remaining_users\n",
    "\n",
    "active_users, remaining_users = filter_users_in_parallel(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter inactive users\n",
    "\n",
    "active_users = []\n",
    "inactive_users = []\n",
    "\n",
    "threshold_day = 180\n",
    "threshold_date = (datetime.now() - timedelta(days=threshold_day)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "with open(f\"./data/users_in_{location}.json\") as file:\n",
    "    users = json.load(file)\n",
    "\n",
    "for idx, user in enumerate(users):\n",
    "    response = requests.get(user[\"url\"], headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        user_info = response.json()\n",
    "        if user_info[\"updated_at\"] > threshold_date:\n",
    "            active_users.append(user)\n",
    "        else:\n",
    "            inactive_users.append(user)\n",
    "    else:\n",
    "        print(f\"Failed to fetch user info: {response.status_code}\")\n",
    "        print(response)\n",
    "        print(\"Waiting for 60 seconds\")\n",
    "        time.sleep(60)\n",
    "\n",
    "    if response.headers.get(\"X-RateLimit-Remaining\") == \"0\" or idx % 100 == 0:\n",
    "        print(\n",
    "            f\"Processed {idx + 1} out of {len(users)} / Total active users: {len(active_users)} / Total inactive users: {len(inactive_users)}\"\n",
    "        )\n",
    "        time.sleep(60)\n",
    "\n",
    "with open(f\"./data/active_users_{location}.json\", \"w\") as file:\n",
    "    json.dump(active_users, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user: savaskancelineProcessing user: KewoLearnsToCode\n",
      "Processing user: Salamvibe\n",
      "Processing user: spgad\n",
      "Processing user: Manu-Pranay\n",
      "Processing user: najdev\n",
      "Processing user: yangrekov\n",
      "Processing user: web3monsta\n",
      "Processing user: kamarapm\n",
      "Processing user: user1\n",
      "Processing user: user2\n",
      "Processing user: user3\n",
      "Processing user: seventeenfkProcessing user: yuzuchrii\n",
      "Processing user: ytessier-clgx\n",
      "Processing user: PiotrSWozniak\n",
      "Processing user: tommyxr-broadsign\n",
      "Processing user: alexandrelavoiedev\n",
      "Processing user: DanCodeCraft\n",
      "Processing user: StephaneBischoffVasco\n",
      "Processing user: v-agapitov\n",
      "Processing user: user4\n",
      "Processing user: justinteixeira\n",
      "Processing user: AghaKianoush\n",
      "Processing user: vovov-2000\n",
      "Processing user: rf9027824\n",
      "Processing user: ColemanWallaceBC\n",
      "Processing user: nikolay-volodin\n",
      "Processing user: tiagans97\n",
      "Processing user: frank-delisle\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     future_to_user \u001b[38;5;241m=\u001b[39m {executor\u001b[38;5;241m.\u001b[39msubmit(process_user, user): user \u001b[38;5;28;01mfor\u001b[39;00m user \u001b[38;5;129;01min\u001b[39;00m users}\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mas_completed(future_to_user):\n\u001b[1;32m     18\u001b[0m         status, user \u001b[38;5;241m=\u001b[39m future\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.11/concurrent/futures/_base.py:243\u001b[0m, in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wait_timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[1;32m    240\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) futures unfinished\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    241\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[0;32m--> 243\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m waiter\u001b[38;5;241m.\u001b[39mlock:\n\u001b[1;32m    246\u001b[0m     finished \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39mfinished_futures\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.11/threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    620\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 622\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user: jeanettelundstromProcessing user: OlivierMayrandTT\n",
      "\n",
      "Processing user: mikel-doucet\n",
      "Processing user: LAhoyos\n",
      "Processing user: ShibamOSCP\n",
      "Processing user: KhalilBTW\n",
      "Processing user: mederickb\n",
      "Processing user: arnav-singh-ahlawat\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "\n",
    "def process_user(user):\n",
    "    print(f\"Processing user: {user['login']}\")\n",
    "    time.sleep(3)\n",
    "    return (\"active\", user)\n",
    "\n",
    "\n",
    "users = [{\"login\": \"user1\"}, {\"login\": \"user2\"}, {\"login\": \"user3\"}, {\"login\": \"user4\"}]\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "\n",
    "    try:\n",
    "        future_to_user = {executor.submit(process_user, user): user for user in users}\n",
    "        for future in concurrent.futures.as_completed(future_to_user):\n",
    "            status, user = future.result()\n",
    "            print(\"test\")\n",
    "    finally:\n",
    "        executor.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch active repos"
<<<<<<< HEAD
>>>>>>> ab00ed3 (fetch and filter users)
=======
>>>>>>> ab00ed3 (fetch and filter users)
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
    "# get repo list that is not forked\n",
=======
>>>>>>> ab00ed3 (fetch and filter users)
=======
>>>>>>> ab00ed3 (fetch and filter users)
    "import requests\n",
    "\n",
    "# URL for the GitHub user's repositories\n",
    "url = \"https://api.github.com/users/minki-j/repos\"\n",
    "\n",
    "# Send the GET request to the GitHub API\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON response\n",
    "    repos = response.json()\n",
    "\n",
    "    # Filter out forked repositories\n",
    "    non_forked_repos = [repo for repo in repos if not repo[\"fork\"]]\n",
    "\n",
    "    # Print the non-forked repositories\n",
    "    for repo in non_forked_repos:\n",
    "        print(f\"Name: {repo['name']}, URL: {repo['html_url']}\")\n",
    "else:\n",
    "    print(f\"Failed to fetch repositories: {response.status_code}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
